# -*- coding: utf-8 -*-
"""
===================================
æ•°æ®æºåŸºç±»ä¸ç®¡ç†å™¨
===================================

è®¾è®¡æ¨¡å¼ï¼šç­–ç•¥æ¨¡å¼ (Strategy Pattern)
- BaseFetcher: æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰ç»Ÿä¸€æ¥å£
- DataFetcherManager: ç­–ç•¥ç®¡ç†å™¨ï¼Œå®ç°è‡ªåŠ¨åˆ‡æ¢

é˜²å°ç¦ç­–ç•¥ï¼š
1. æ¯ä¸ª Fetcher å†…ç½®æµæ§é€»è¾‘
2. å¤±è´¥è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæ•°æ®æº
3. æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶
"""

import logging
import random
import time
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Optional, List, Tuple, Dict, Any

import pandas as pd
import numpy as np
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


# === æ ‡å‡†åŒ–åˆ—åå®šä¹‰ ===
STANDARD_COLUMNS = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'pct_chg']


class DataFetchError(Exception):
    """æ•°æ®è·å–å¼‚å¸¸åŸºç±»"""
    pass


class RateLimitError(DataFetchError):
    """API é€Ÿç‡é™åˆ¶å¼‚å¸¸"""
    pass


class DataSourceUnavailableError(DataFetchError):
    """æ•°æ®æºä¸å¯ç”¨å¼‚å¸¸"""
    pass


class BaseFetcher(ABC):
    """
    æ•°æ®æºæŠ½è±¡åŸºç±»
    
    èŒè´£ï¼š
    1. å®šä¹‰ç»Ÿä¸€çš„æ•°æ®è·å–æ¥å£
    2. æä¾›æ•°æ®æ ‡å‡†åŒ–æ–¹æ³•
    3. å®ç°é€šç”¨çš„æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
    
    å­ç±»å®ç°ï¼š
    - _fetch_raw_data(): ä»å…·ä½“æ•°æ®æºè·å–åŸå§‹æ•°æ®
    - _normalize_data(): å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    """
    
    name: str = "BaseFetcher"
    priority: int = 99  # ä¼˜å…ˆçº§æ•°å­—è¶Šå°è¶Šä¼˜å…ˆ
    
    @abstractmethod
    def _fetch_raw_data(self, stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        ä»æ•°æ®æºè·å–åŸå§‹æ•°æ®ï¼ˆå­ç±»å¿…é¡»å®ç°ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '600519', '000001'
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
            
        Returns:
            åŸå§‹æ•°æ® DataFrameï¼ˆåˆ—åå› æ•°æ®æºè€Œå¼‚ï¼‰
        """
        pass
    
    @abstractmethod
    def _normalize_data(self, df: pd.DataFrame, stock_code: str) -> pd.DataFrame:
        """
        æ ‡å‡†åŒ–æ•°æ®åˆ—åï¼ˆå­ç±»å¿…é¡»å®ç°ï¼‰

        å°†ä¸åŒæ•°æ®æºçš„åˆ—åç»Ÿä¸€ä¸ºï¼š
        ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'pct_chg']
        """
        pass

    def get_main_indices(self) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–ä¸»è¦æŒ‡æ•°å®æ—¶è¡Œæƒ…

        Returns:
            List[Dict]: æŒ‡æ•°åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå­—å…¸ï¼ŒåŒ…å«:
                - code: æŒ‡æ•°ä»£ç 
                - name: æŒ‡æ•°åç§°
                - current: å½“å‰ç‚¹ä½
                - change: æ¶¨è·Œç‚¹æ•°
                - change_pct: æ¶¨è·Œå¹…(%)
                - volume: æˆäº¤é‡
                - amount: æˆäº¤é¢
        """
        return None

    def get_market_stats(self) -> Optional[Dict[str, Any]]:
        """
        è·å–å¸‚åœºæ¶¨è·Œç»Ÿè®¡

        Returns:
            Dict: åŒ…å«:
                - up_count: ä¸Šæ¶¨å®¶æ•°
                - down_count: ä¸‹è·Œå®¶æ•°
                - flat_count: å¹³ç›˜å®¶æ•°
                - limit_up_count: æ¶¨åœå®¶æ•°
                - limit_down_count: è·Œåœå®¶æ•°
                - total_amount: ä¸¤å¸‚æˆäº¤é¢
        """
        return None

    def get_sector_rankings(self, n: int = 5) -> Optional[Tuple[List[Dict], List[Dict]]]:
        """
        è·å–æ¿å—æ¶¨è·Œæ¦œ

        Args:
            n: è¿”å›å‰nä¸ª

        Returns:
            Tuple: (é¢†æ¶¨æ¿å—åˆ—è¡¨, é¢†è·Œæ¿å—åˆ—è¡¨)
        """
        return None

    def get_daily_data(
        self,
        stock_code: str, 
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        days: int = 30
    ) -> pd.DataFrame:
        """
        è·å–æ—¥çº¿æ•°æ®ï¼ˆç»Ÿä¸€å…¥å£ï¼‰
        
        æµç¨‹ï¼š
        1. è®¡ç®—æ—¥æœŸèŒƒå›´
        2. è°ƒç”¨å­ç±»è·å–åŸå§‹æ•°æ®
        3. æ ‡å‡†åŒ–åˆ—å
        4. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
            days: è·å–å¤©æ•°ï¼ˆå½“ start_date æœªæŒ‡å®šæ—¶ä½¿ç”¨ï¼‰
            
        Returns:
            æ ‡å‡†åŒ–çš„ DataFrameï¼ŒåŒ…å«æŠ€æœ¯æŒ‡æ ‡
        """
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        if end_date is None:
            end_date = datetime.now().strftime('%Y-%m-%d')
        
        if start_date is None:
            # é»˜è®¤è·å–æœ€è¿‘ 30 ä¸ªäº¤æ˜“æ—¥ï¼ˆæŒ‰æ—¥å†æ—¥ä¼°ç®—ï¼Œå¤šå–ä¸€äº›ï¼‰
            from datetime import timedelta
            start_dt = datetime.strptime(end_date, '%Y-%m-%d') - timedelta(days=days * 2)
            start_date = start_dt.strftime('%Y-%m-%d')
        
        logger.info(f"[{self.name}] è·å– {stock_code} æ•°æ®: {start_date} ~ {end_date}")
        
        try:
            # Step 1: è·å–åŸå§‹æ•°æ®
            raw_df = self._fetch_raw_data(stock_code, start_date, end_date)
            
            if raw_df is None or raw_df.empty:
                raise DataFetchError(f"[{self.name}] æœªè·å–åˆ° {stock_code} çš„æ•°æ®")
            
            # Step 2: æ ‡å‡†åŒ–åˆ—å
            df = self._normalize_data(raw_df, stock_code)
            
            # Step 3: æ•°æ®æ¸…æ´—
            df = self._clean_data(df)
            
            # Step 4: è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            df = self._calculate_indicators(df)
            
            logger.info(f"[{self.name}] {stock_code} è·å–æˆåŠŸï¼Œå…± {len(df)} æ¡æ•°æ®")
            return df
            
        except Exception as e:
            logger.error(f"[{self.name}] è·å– {stock_code} å¤±è´¥: {str(e)}")
            raise DataFetchError(f"[{self.name}] {stock_code}: {str(e)}") from e
    
    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ•°æ®æ¸…æ´—
        
        å¤„ç†ï¼š
        1. ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼æ­£ç¡®
        2. æ•°å€¼ç±»å‹è½¬æ¢
        3. å»é™¤ç©ºå€¼è¡Œ
        4. æŒ‰æ—¥æœŸæ’åº
        """
        df = df.copy()
        
        # ç¡®ä¿æ—¥æœŸåˆ—ä¸º datetime ç±»å‹
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'])
        
        # æ•°å€¼åˆ—ç±»å‹è½¬æ¢
        numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'amount', 'pct_chg']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # å»é™¤å…³é”®åˆ—ä¸ºç©ºçš„è¡Œ
        df = df.dropna(subset=['close', 'volume'])
        
        # æŒ‰æ—¥æœŸå‡åºæ’åº
        df = df.sort_values('date', ascending=True).reset_index(drop=True)
        
        return df
    
    def _calculate_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        
        è®¡ç®—æŒ‡æ ‡ï¼š
        - MA5, MA10, MA20: ç§»åŠ¨å¹³å‡çº¿
        - Volume_Ratio: é‡æ¯”ï¼ˆä»Šæ—¥æˆäº¤é‡ / 5æ—¥å¹³å‡æˆäº¤é‡ï¼‰
        """
        df = df.copy()
        
        # ç§»åŠ¨å¹³å‡çº¿
        df['ma5'] = df['close'].rolling(window=5, min_periods=1).mean()
        df['ma10'] = df['close'].rolling(window=10, min_periods=1).mean()
        df['ma20'] = df['close'].rolling(window=20, min_periods=1).mean()
        
        # é‡æ¯”ï¼šå½“æ—¥æˆäº¤é‡ / 5æ—¥å¹³å‡æˆäº¤é‡
        avg_volume_5 = df['volume'].rolling(window=5, min_periods=1).mean()
        df['volume_ratio'] = df['volume'] / avg_volume_5.shift(1)
        df['volume_ratio'] = df['volume_ratio'].fillna(1.0)
        
        # ä¿ç•™2ä½å°æ•°
        for col in ['ma5', 'ma10', 'ma20', 'volume_ratio']:
            if col in df.columns:
                df[col] = df[col].round(2)
        
        return df
    
    @staticmethod
    def random_sleep(min_seconds: float = 1.0, max_seconds: float = 3.0) -> None:
        """
        æ™ºèƒ½éšæœºä¼‘çœ ï¼ˆJitterï¼‰
        
        é˜²å°ç¦ç­–ç•¥ï¼šæ¨¡æ‹Ÿäººç±»è¡Œä¸ºçš„éšæœºå»¶è¿Ÿ
        åœ¨è¯·æ±‚ä¹‹é—´åŠ å…¥ä¸è§„åˆ™çš„ç­‰å¾…æ—¶é—´
        """
        sleep_time = random.uniform(min_seconds, max_seconds)
        logger.debug(f"éšæœºä¼‘çœ  {sleep_time:.2f} ç§’...")
        time.sleep(sleep_time)


class DataFetcherManager:
    """
    æ•°æ®æºç­–ç•¥ç®¡ç†å™¨
    
    èŒè´£ï¼š
    1. ç®¡ç†å¤šä¸ªæ•°æ®æºï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    2. è‡ªåŠ¨æ•…éšœåˆ‡æ¢ï¼ˆFailoverï¼‰
    3. æä¾›ç»Ÿä¸€çš„æ•°æ®è·å–æ¥å£
    
    åˆ‡æ¢ç­–ç•¥ï¼š
    - ä¼˜å…ˆä½¿ç”¨é«˜ä¼˜å…ˆçº§æ•°æ®æº
    - å¤±è´¥åè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª
    - æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    
    def __init__(self, fetchers: Optional[List[BaseFetcher]] = None):
        """
        åˆå§‹åŒ–ç®¡ç†å™¨
        
        Args:
            fetchers: æ•°æ®æºåˆ—è¡¨ï¼ˆå¯é€‰ï¼Œé»˜è®¤æŒ‰ä¼˜å…ˆçº§è‡ªåŠ¨åˆ›å»ºï¼‰
        """
        self._fetchers: List[BaseFetcher] = []
        
        if fetchers:
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            self._fetchers = sorted(fetchers, key=lambda f: f.priority)
        else:
            # é»˜è®¤æ•°æ®æºå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶å»¶è¿ŸåŠ è½½
            self._init_default_fetchers()
    
    def _init_default_fetchers(self) -> None:
        """
        åˆå§‹åŒ–é»˜è®¤æ•°æ®æºåˆ—è¡¨

        ä¼˜å…ˆçº§åŠ¨æ€è°ƒæ•´é€»è¾‘ï¼š
        - å¦‚æœé…ç½®äº† TUSHARE_TOKENï¼šTushare ä¼˜å…ˆçº§æå‡ä¸º 0ï¼ˆæœ€é«˜ï¼‰
        - å¦åˆ™æŒ‰é»˜è®¤ä¼˜å…ˆçº§ï¼š
          0. EfinanceFetcher (Priority 0) - æœ€é«˜ä¼˜å…ˆçº§
          1. AkshareFetcher (Priority 1)
          2. PytdxFetcher (Priority 2) - é€šè¾¾ä¿¡
          2. TushareFetcher (Priority 2)
          3. BaostockFetcher (Priority 3)
          4. YfinanceFetcher (Priority 4)
        """
        from .efinance_fetcher import EfinanceFetcher
        from .akshare_fetcher import AkshareFetcher
        from .tushare_fetcher import TushareFetcher
        from .pytdx_fetcher import PytdxFetcher
        from .baostock_fetcher import BaostockFetcher
        from .yfinance_fetcher import YfinanceFetcher
        from src.config import get_config

        config = get_config()

        # åˆ›å»ºæ‰€æœ‰æ•°æ®æºå®ä¾‹ï¼ˆä¼˜å…ˆçº§åœ¨å„ Fetcher çš„ __init__ ä¸­ç¡®å®šï¼‰
        efinance = EfinanceFetcher()
        akshare = AkshareFetcher()
        tushare = TushareFetcher()  # ä¼šæ ¹æ® Token é…ç½®è‡ªåŠ¨è°ƒæ•´ä¼˜å…ˆçº§
        pytdx = PytdxFetcher()      # é€šè¾¾ä¿¡æ•°æ®æº
        baostock = BaostockFetcher()
        yfinance = YfinanceFetcher()

        # åˆå§‹åŒ–æ•°æ®æºåˆ—è¡¨
        self._fetchers = [
            efinance,
            akshare,
            tushare,
            pytdx,
            baostock,
            yfinance,
        ]

        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆTushare å¦‚æœé…ç½®äº† Token ä¸”åˆå§‹åŒ–æˆåŠŸï¼Œä¼˜å…ˆçº§ä¸º 0ï¼‰
        self._fetchers.sort(key=lambda f: f.priority)

        # æ„å»ºä¼˜å…ˆçº§è¯´æ˜
        priority_info = ", ".join([f"{f.name}(P{f.priority})" for f in self._fetchers])
        logger.info(f"å·²åˆå§‹åŒ– {len(self._fetchers)} ä¸ªæ•°æ®æºï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰: {priority_info}")
    
    def add_fetcher(self, fetcher: BaseFetcher) -> None:
        """æ·»åŠ æ•°æ®æºå¹¶é‡æ–°æ’åº"""
        self._fetchers.append(fetcher)
        self._fetchers.sort(key=lambda f: f.priority)
    
    def get_daily_data(
        self, 
        stock_code: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        days: int = 30
    ) -> Tuple[pd.DataFrame, str]:
        """
        è·å–æ—¥çº¿æ•°æ®ï¼ˆè‡ªåŠ¨åˆ‡æ¢æ•°æ®æºï¼‰
        
        æ•…éšœåˆ‡æ¢ç­–ç•¥ï¼š
        1. ä»æœ€é«˜ä¼˜å…ˆçº§æ•°æ®æºå¼€å§‹å°è¯•
        2. æ•è·å¼‚å¸¸åè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª
        3. è®°å½•æ¯ä¸ªæ•°æ®æºçš„å¤±è´¥åŸå› 
        4. æ‰€æœ‰æ•°æ®æºå¤±è´¥åæŠ›å‡ºè¯¦ç»†å¼‚å¸¸
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            days: è·å–å¤©æ•°
            
        Returns:
            Tuple[DataFrame, str]: (æ•°æ®, æˆåŠŸçš„æ•°æ®æºåç§°)
            
        Raises:
            DataFetchError: æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥æ—¶æŠ›å‡º
        """
        errors = []
        
        for fetcher in self._fetchers:
            # === æ ¸å¿ƒä¿®æ”¹ï¼šæ™ºèƒ½åˆ†æµ (Start) ===
            # å¦‚æœæ˜¯æ¾³æ´²è‚¡ç¥¨(.AX) æˆ– ç¾è‚¡(çº¯å­—æ¯)ï¼Œä¸”å½“å‰å·¥å…·ä¸æ˜¯é›…è™ï¼Œç›´æ¥è·³è¿‡
            is_au_us = ('.AX' in stock_code) or (stock_code.isalpha()) or ('.US' in stock_code)
            
            if is_au_us and 'YfinanceFetcher' not in fetcher.name:
                continue
            # === æ ¸å¿ƒä¿®æ”¹ï¼šæ™ºèƒ½åˆ†æµ (End) ===

            try:
                logger.info(f"å°è¯•ä½¿ç”¨ [{fetcher.name}] è·å– {stock_code}...")
                
                # ğŸ‘‡ğŸ‘‡ğŸ‘‡ è¿™é‡Œæ˜¯ä½ åˆšæ‰æ¼æ‰çš„å…³é”®ä»£ç ï¼Œå¿…é¡»åŠ å›æ¥ï¼ ğŸ‘‡ğŸ‘‡ğŸ‘‡
                df = fetcher.get_daily_data(
                    stock_code=stock_code,
                    start_date=start_date,
                    end_date=end_date,
                    days=days
                )
                # ğŸ‘†ğŸ‘†ğŸ‘† æ²¡æœ‰è¿™ä¸€æ®µï¼Œç¨‹åºå°±åºŸäº† ğŸ‘†ğŸ‘†ğŸ‘†

                if df is not None and not df.empty:
                    logger.info(f"[{fetcher.name}] æˆåŠŸè·å– {stock_code}")
                    return df, fetcher.name
                    
            except Exception as e:
                error_msg = f"[{fetcher.name}] å¤±è´¥: {str(e)}"
                logger.warning(error_msg)
                errors.append(error_msg)
                # ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªæ•°æ®æº
                continue
        
        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥
        error_summary = f"æ‰€æœ‰æ•°æ®æºè·å– {stock_code} å¤±è´¥:\n" + "\n".join(errors)
        logger.error(error_summary)
        raise DataFetchError(error_summary)
    
    @property
    def available_fetchers(self) -> List[str]:
        """è¿”å›å¯ç”¨æ•°æ®æºåç§°åˆ—è¡¨"""
        return [f.name for f in self._fetchers]
    
    def prefetch_realtime_quotes(self, stock_codes: List[str]) -> int:
        """
        æ‰¹é‡é¢„å–å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆåœ¨åˆ†æå¼€å§‹å‰è°ƒç”¨ï¼‰
        
        ç­–ç•¥ï¼š
        1. æ£€æŸ¥ä¼˜å…ˆçº§ä¸­æ˜¯å¦åŒ…å«å…¨é‡æ‹‰å–æ•°æ®æºï¼ˆefinance/akshare_emï¼‰
        2. å¦‚æœä¸åŒ…å«ï¼Œè·³è¿‡é¢„å–ï¼ˆæ–°æµª/è…¾è®¯æ˜¯å•è‚¡ç¥¨æŸ¥è¯¢ï¼Œæ— éœ€é¢„å–ï¼‰
        3. å¦‚æœè‡ªé€‰è‚¡æ•°é‡ >= 5 ä¸”ä½¿ç”¨å…¨é‡æ•°æ®æºï¼Œåˆ™é¢„å–å¡«å……ç¼“å­˜
        
        è¿™æ ·åšçš„å¥½å¤„ï¼š
        - ä½¿ç”¨æ–°æµª/è…¾è®¯æ—¶ï¼šæ¯åªè‚¡ç¥¨ç‹¬ç«‹æŸ¥è¯¢ï¼Œæ— å…¨é‡æ‹‰å–é—®é¢˜
        - ä½¿ç”¨ efinance/ä¸œè´¢æ—¶ï¼šé¢„å–ä¸€æ¬¡ï¼Œåç»­ç¼“å­˜å‘½ä¸­
        
        Args:
            stock_codes: å¾…åˆ†æçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
            
        Returns:
            é¢„å–çš„è‚¡ç¥¨æ•°é‡ï¼ˆ0 è¡¨ç¤ºè·³è¿‡é¢„å–ï¼‰
        """
        from src.config import get_config
        
        config = get_config()
        
        # å¦‚æœå®æ—¶è¡Œæƒ…è¢«ç¦ç”¨ï¼Œè·³è¿‡é¢„å–
        if not config.enable_realtime_quote:
            logger.debug("[é¢„å–] å®æ—¶è¡Œæƒ…åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡é¢„å–")
            return 0
        
        # æ£€æŸ¥ä¼˜å…ˆçº§ä¸­æ˜¯å¦åŒ…å«å…¨é‡æ‹‰å–æ•°æ®æº
        # æ³¨æ„ï¼šæ–°å¢å…¨é‡æ¥å£ï¼ˆå¦‚ tushare_realtimeï¼‰æ—¶éœ€åŒæ­¥æ›´æ–°æ­¤åˆ—è¡¨
        # å…¨é‡æ¥å£ç‰¹å¾ï¼šä¸€æ¬¡ API è°ƒç”¨æ‹‰å–å…¨å¸‚åœº 5000+ è‚¡ç¥¨æ•°æ®
        priority = config.realtime_source_priority.lower()
        bulk_sources = ['efinance', 'akshare_em', 'tushare']  # å…¨é‡æ¥å£åˆ—è¡¨
        
        # å¦‚æœä¼˜å…ˆçº§ä¸­å‰ä¸¤ä¸ªéƒ½ä¸æ˜¯å…¨é‡æ•°æ®æºï¼Œè·³è¿‡é¢„å–
        # å› ä¸ºæ–°æµª/è…¾è®¯æ˜¯å•è‚¡ç¥¨æŸ¥è¯¢ï¼Œä¸éœ€è¦é¢„å–
        priority_list = [s.strip() for s in priority.split(',')]
        first_bulk_source_index = None
        for i, source in enumerate(priority_list):
            if source in bulk_sources:
                first_bulk_source_index = i
                break
        
        # å¦‚æœæ²¡æœ‰å…¨é‡æ•°æ®æºï¼Œæˆ–è€…å…¨é‡æ•°æ®æºæ’åœ¨ç¬¬ 3 ä½ä¹‹åï¼Œè·³è¿‡é¢„å–
        if first_bulk_source_index is None or first_bulk_source_index >= 2:
            logger.info(f"[é¢„å–] å½“å‰ä¼˜å…ˆçº§ä½¿ç”¨è½»é‡çº§æ•°æ®æº(sina/tencent)ï¼Œæ— éœ€é¢„å–")
            return 0
        
        # å¦‚æœè‚¡ç¥¨æ•°é‡å°‘äº 5 ä¸ªï¼Œä¸è¿›è¡Œæ‰¹é‡é¢„å–ï¼ˆé€ä¸ªæŸ¥è¯¢æ›´é«˜æ•ˆï¼‰
        if len(stock_codes) < 5:
            logger.info(f"[é¢„å–] è‚¡ç¥¨æ•°é‡ {len(stock_codes)} < 5ï¼Œè·³è¿‡æ‰¹é‡é¢„å–")
            return 0
        
        logger.info(f"[é¢„å–] å¼€å§‹æ‰¹é‡é¢„å–å®æ—¶è¡Œæƒ…ï¼Œå…± {len(stock_codes)} åªè‚¡ç¥¨...")
        
        # å°è¯•é€šè¿‡ efinance æˆ– akshare é¢„å–
        # åªéœ€è¦è°ƒç”¨ä¸€æ¬¡ get_realtime_quoteï¼Œç¼“å­˜æœºåˆ¶ä¼šè‡ªåŠ¨æ‹‰å–å…¨å¸‚åœºæ•°æ®
        try:
            # ç”¨ç¬¬ä¸€åªè‚¡ç¥¨è§¦å‘å…¨é‡æ‹‰å–
            first_code = stock_codes[0]
            quote = self.get_realtime_quote(first_code)
            
            if quote:
                logger.info(f"[é¢„å–] æ‰¹é‡é¢„å–å®Œæˆï¼Œç¼“å­˜å·²å¡«å……")
                return len(stock_codes)
            else:
                logger.warning(f"[é¢„å–] æ‰¹é‡é¢„å–å¤±è´¥ï¼Œå°†ä½¿ç”¨é€ä¸ªæŸ¥è¯¢æ¨¡å¼")
                return 0
                
        except Exception as e:
            logger.error(f"[é¢„å–] æ‰¹é‡é¢„å–å¼‚å¸¸: {e}")
            return 0
    
    def get_realtime_quote(self, stock_code: str):
        """
        è·å–å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆè‡ªåŠ¨æ•…éšœåˆ‡æ¢ï¼‰
        
        æ•…éšœåˆ‡æ¢ç­–ç•¥ï¼ˆæŒ‰é…ç½®çš„ä¼˜å…ˆçº§ï¼‰ï¼š
        1. ç¾è‚¡ï¼šä½¿ç”¨ YfinanceFetcher.get_realtime_quote()
        2. EfinanceFetcher.get_realtime_quote()
        3. AkshareFetcher.get_realtime_quote(source="em")  - ä¸œè´¢
        4. AkshareFetcher.get_realtime_quote(source="sina") - æ–°æµª
        5. AkshareFetcher.get_realtime_quote(source="tencent") - è…¾è®¯
        6. è¿”å› Noneï¼ˆé™çº§å…œåº•ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            UnifiedRealtimeQuote å¯¹è±¡ï¼Œæ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥åˆ™è¿”å› None
        """
        from .realtime_types import get_realtime_circuit_breaker
        from .akshare_fetcher import _is_us_code
        from src.config import get_config
        
        config = get_config()
        
        # å¦‚æœå®æ—¶è¡Œæƒ…åŠŸèƒ½è¢«ç¦ç”¨ï¼Œç›´æ¥è¿”å› None
        if not config.enable_realtime_quote:
            logger.debug(f"[å®æ—¶è¡Œæƒ…] åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡ {stock_code}")
            return None
        
        # ç¾è‚¡å•ç‹¬å¤„ç†ï¼Œä½¿ç”¨ YfinanceFetcher
        if _is_us_code(stock_code):
            for fetcher in self._fetchers:
                if fetcher.name == "YfinanceFetcher":
                    if hasattr(fetcher, 'get_realtime_quote'):
                        try:
                            quote = fetcher.get_realtime_quote(stock_code)
                            if quote is not None:
                                logger.info(f"[å®æ—¶è¡Œæƒ…] ç¾è‚¡ {stock_code} æˆåŠŸè·å– (æ¥æº: yfinance)")
                                return quote
                        except Exception as e:
                            logger.warning(f"[å®æ—¶è¡Œæƒ…] ç¾è‚¡ {stock_code} è·å–å¤±è´¥: {e}")
                    break
            logger.warning(f"[å®æ—¶è¡Œæƒ…] ç¾è‚¡ {stock_code} æ— å¯ç”¨æ•°æ®æº")
            return None
        
        # è·å–é…ç½®çš„æ•°æ®æºä¼˜å…ˆçº§
        source_priority = config.realtime_source_priority.split(',')
        
        errors = []
        # primary_quote holds the first successful result; we may supplement
        # missing fields (volume_ratio, turnover_rate, etc.) from later sources.
        primary_quote = None
        
        for source in source_priority:
            source = source.strip().lower()
            
            try:
                quote = None
                
                if source == "efinance":
                    # å°è¯• EfinanceFetcher
                    for fetcher in self._fetchers:
                        if fetcher.name == "EfinanceFetcher":
                            if hasattr(fetcher, 'get_realtime_quote'):
                                quote = fetcher.get_realtime_quote(stock_code)
                            break
                
                elif source == "akshare_em":
                    # å°è¯• AkshareFetcher ä¸œè´¢æ•°æ®æº
                    for fetcher in self._fetchers:
                        if fetcher.name == "AkshareFetcher":
                            if hasattr(fetcher, 'get_realtime_quote'):
                                quote = fetcher.get_realtime_quote(stock_code, source="em")
                            break
                
                elif source == "akshare_sina":
                    # å°è¯• AkshareFetcher æ–°æµªæ•°æ®æº
                    for fetcher in self._fetchers:
                        if fetcher.name == "AkshareFetcher":
                            if hasattr(fetcher, 'get_realtime_quote'):
                                quote = fetcher.get_realtime_quote(stock_code, source="sina")
                            break
                
                elif source in ("tencent", "akshare_qq"):
                    # å°è¯• AkshareFetcher è…¾è®¯æ•°æ®æº
                    for fetcher in self._fetchers:
                        if fetcher.name == "AkshareFetcher":
                            if hasattr(fetcher, 'get_realtime_quote'):
                                quote = fetcher.get_realtime_quote(stock_code, source="tencent")
                            break
                
                elif source == "tushare":
                    # å°è¯• TushareFetcherï¼ˆéœ€è¦ Tushare Pro ç§¯åˆ†ï¼‰
                    for fetcher in self._fetchers:
                        if fetcher.name == "TushareFetcher":
                            if hasattr(fetcher, 'get_realtime_quote'):
                                quote = fetcher.get_realtime_quote(stock_code)
                            break
                
                if quote is not None and quote.has_basic_data():
                    if primary_quote is None:
                        # First successful source becomes primary
                        primary_quote = quote
                        logger.info(f"[å®æ—¶è¡Œæƒ…] {stock_code} æˆåŠŸè·å– (æ¥æº: {source})")
                        # If all key supplementary fields are present, return early
                        if not self._quote_needs_supplement(primary_quote):
                            return primary_quote
                        # Otherwise, continue to try later sources for missing fields
                        logger.debug(f"[å®æ—¶è¡Œæƒ…] {stock_code} éƒ¨åˆ†å­—æ®µç¼ºå¤±ï¼Œå°è¯•ä»åç»­æ•°æ®æºè¡¥å……")
                        supplement_attempts = 0
                    else:
                        # Supplement missing fields from this source (limit attempts)
                        supplement_attempts += 1
                        if supplement_attempts > 1:
                            logger.debug(f"[å®æ—¶è¡Œæƒ…] {stock_code} è¡¥å……å°è¯•å·²è¾¾ä¸Šé™ï¼Œåœæ­¢ç»§ç»­")
                            break
                        merged = self._merge_quote_fields(primary_quote, quote)
                        if merged:
                            logger.info(f"[å®æ—¶è¡Œæƒ…] {stock_code} ä» {source} è¡¥å……äº†ç¼ºå¤±å­—æ®µ: {merged}")
                        # Stop supplementing once all key fields are filled
                        if not self._quote_needs_supplement(primary_quote):
                            break
                    
            except Exception as e:
                error_msg = f"[{source}] å¤±è´¥: {str(e)}"
                logger.warning(error_msg)
                errors.append(error_msg)
                continue
        
        # Return primary even if some fields are still missing
        if primary_quote is not None:
            return primary_quote

        # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œè¿”å› Noneï¼ˆé™çº§å…œåº•ï¼‰
        if errors:
            logger.warning(f"[å®æ—¶è¡Œæƒ…] {stock_code} æ‰€æœ‰æ•°æ®æºå‡å¤±è´¥ï¼Œé™çº§å¤„ç†: {'; '.join(errors)}")
        else:
            logger.warning(f"[å®æ—¶è¡Œæƒ…] {stock_code} æ— å¯ç”¨æ•°æ®æº")
        
        return None

    # Fields worth supplementing from secondary sources when the primary
    # source returns None for them. Ordered by importance.
    _SUPPLEMENT_FIELDS = [
        'volume_ratio', 'turnover_rate',
        'pe_ratio', 'pb_ratio', 'total_mv', 'circ_mv',
        'amplitude',
    ]

    @classmethod
    def _quote_needs_supplement(cls, quote) -> bool:
        """Check if any key supplementary field is still None."""
        for f in cls._SUPPLEMENT_FIELDS:
            if getattr(quote, f, None) is None:
                return True
        return False

    @classmethod
    def _merge_quote_fields(cls, primary, secondary) -> list:
        """
        Copy non-None fields from *secondary* into *primary* where
        *primary* has None. Returns list of field names that were filled.
        """
        filled = []
        for f in cls._SUPPLEMENT_FIELDS:
            if getattr(primary, f, None) is None:
                val = getattr(secondary, f, None)
                if val is not None:
                    setattr(primary, f, val)
                    filled.append(f)
        return filled

    def get_chip_distribution(self, stock_code: str):
        """
        è·å–ç­¹ç åˆ†å¸ƒæ•°æ®ï¼ˆå¸¦ç†”æ–­å’Œå¤šæ•°æ®æºé™çº§ï¼‰

        ç­–ç•¥ï¼š
        1. æ£€æŸ¥é…ç½®å¼€å…³
        2. æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
        3. ä¾æ¬¡å°è¯•å¤šä¸ªæ•°æ®æºï¼šAkshareFetcher -> TushareFetcher -> EfinanceFetcher
        4. æ‰€æœ‰æ•°æ®æºå¤±è´¥åˆ™è¿”å› Noneï¼ˆé™çº§å…œåº•ï¼‰

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 

        Returns:
            ChipDistribution å¯¹è±¡ï¼Œå¤±è´¥åˆ™è¿”å› None
        """
        from .realtime_types import get_chip_circuit_breaker
        from src.config import get_config

        config = get_config()

        # å¦‚æœç­¹ç åˆ†å¸ƒåŠŸèƒ½è¢«ç¦ç”¨ï¼Œç›´æ¥è¿”å› None
        if not config.enable_chip_distribution:
            logger.debug(f"[ç­¹ç åˆ†å¸ƒ] åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡ {stock_code}")
            return None

        circuit_breaker = get_chip_circuit_breaker()

        # å®šä¹‰ç­¹ç æ•°æ®æºä¼˜å…ˆçº§åˆ—è¡¨
        chip_sources = [
            ("AkshareFetcher", "akshare_chip"),
            ("TushareFetcher", "tushare_chip"),
            ("EfinanceFetcher", "efinance_chip"),
        ]

        for fetcher_name, source_key in chip_sources:
            # æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
            if not circuit_breaker.is_available(source_key):
                logger.debug(f"[ç†”æ–­] {fetcher_name} ç­¹ç æ¥å£å¤„äºç†”æ–­çŠ¶æ€ï¼Œå°è¯•ä¸‹ä¸€ä¸ª")
                continue

            try:
                for fetcher in self._fetchers:
                    if fetcher.name == fetcher_name:
                        if hasattr(fetcher, 'get_chip_distribution'):
                            chip = fetcher.get_chip_distribution(stock_code)
                            if chip is not None:
                                circuit_breaker.record_success(source_key)
                                logger.info(f"[ç­¹ç åˆ†å¸ƒ] {stock_code} æˆåŠŸè·å– (æ¥æº: {fetcher_name})")
                                return chip
                        break
            except Exception as e:
                logger.warning(f"[ç­¹ç åˆ†å¸ƒ] {fetcher_name} è·å– {stock_code} å¤±è´¥: {e}")
                circuit_breaker.record_failure(source_key, str(e))
                continue

        logger.warning(f"[ç­¹ç åˆ†å¸ƒ] {stock_code} æ‰€æœ‰æ•°æ®æºå‡å¤±è´¥")
        return None

    def get_stock_name(self, stock_code: str) -> Optional[str]:
        """
        è·å–è‚¡ç¥¨ä¸­æ–‡åç§°ï¼ˆè‡ªåŠ¨åˆ‡æ¢æ•°æ®æºï¼‰
        
        å°è¯•ä»å¤šä¸ªæ•°æ®æºè·å–è‚¡ç¥¨åç§°ï¼š
        1. å…ˆä»å®æ—¶è¡Œæƒ…ç¼“å­˜ä¸­è·å–ï¼ˆå¦‚æœæœ‰ï¼‰
        2. ä¾æ¬¡å°è¯•å„ä¸ªæ•°æ®æºçš„ get_stock_name æ–¹æ³•
        3. æœ€åå°è¯•è®©å¤§æ¨¡å‹é€šè¿‡æœç´¢è·å–ï¼ˆéœ€è¦å¤–éƒ¨è°ƒç”¨ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            è‚¡ç¥¨ä¸­æ–‡åç§°ï¼Œæ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥åˆ™è¿”å› None
        """
        # 1. å…ˆæ£€æŸ¥ç¼“å­˜
        if hasattr(self, '_stock_name_cache') and stock_code in self._stock_name_cache:
            return self._stock_name_cache[stock_code]
        
        # åˆå§‹åŒ–ç¼“å­˜
        if not hasattr(self, '_stock_name_cache'):
            self._stock_name_cache = {}
        
        # 2. å°è¯•ä»å®æ—¶è¡Œæƒ…ä¸­è·å–ï¼ˆæœ€å¿«ï¼‰
        quote = self.get_realtime_quote(stock_code)
        if quote and hasattr(quote, 'name') and quote.name:
            name = quote.name
            self._stock_name_cache[stock_code] = name
            logger.info(f"[è‚¡ç¥¨åç§°] ä»å®æ—¶è¡Œæƒ…è·å–: {stock_code} -> {name}")
            return name
        
        # 3. ä¾æ¬¡å°è¯•å„ä¸ªæ•°æ®æº
        for fetcher in self._fetchers:
            if hasattr(fetcher, 'get_stock_name'):
                try:
                    name = fetcher.get_stock_name(stock_code)
                    if name:
                        self._stock_name_cache[stock_code] = name
                        logger.info(f"[è‚¡ç¥¨åç§°] ä» {fetcher.name} è·å–: {stock_code} -> {name}")
                        return name
                except Exception as e:
                    logger.debug(f"[è‚¡ç¥¨åç§°] {fetcher.name} è·å–å¤±è´¥: {e}")
                    continue
        
        # 4. æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥
        logger.warning(f"[è‚¡ç¥¨åç§°] æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å– {stock_code} çš„åç§°")
        return None

    def batch_get_stock_names(self, stock_codes: List[str]) -> Dict[str, str]:
        """
        æ‰¹é‡è·å–è‚¡ç¥¨ä¸­æ–‡åç§°
        
        å…ˆå°è¯•ä»æ”¯æŒæ‰¹é‡æŸ¥è¯¢çš„æ•°æ®æºè·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œ
        ç„¶åå†é€ä¸ªæŸ¥è¯¢ç¼ºå¤±çš„è‚¡ç¥¨åç§°ã€‚
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            
        Returns:
            {è‚¡ç¥¨ä»£ç : è‚¡ç¥¨åç§°} å­—å…¸
        """
        result = {}
        missing_codes = set(stock_codes)
        
        # 1. å…ˆæ£€æŸ¥ç¼“å­˜
        if not hasattr(self, '_stock_name_cache'):
            self._stock_name_cache = {}
        
        for code in stock_codes:
            if code in self._stock_name_cache:
                result[code] = self._stock_name_cache[code]
                missing_codes.discard(code)
        
        if not missing_codes:
            return result
        
        # 2. å°è¯•æ‰¹é‡è·å–è‚¡ç¥¨åˆ—è¡¨
        for fetcher in self._fetchers:
            if hasattr(fetcher, 'get_stock_list') and missing_codes:
                try:
                    stock_list = fetcher.get_stock_list()
                    if stock_list is not None and not stock_list.empty:
                        for _, row in stock_list.iterrows():
                            code = row.get('code')
                            name = row.get('name')
                            if code and name:
                                self._stock_name_cache[code] = name
                                if code in missing_codes:
                                    result[code] = name
                                    missing_codes.discard(code)
                        
                        if not missing_codes:
                            break
                        
                        logger.info(f"[è‚¡ç¥¨åç§°] ä» {fetcher.name} æ‰¹é‡è·å–å®Œæˆï¼Œå‰©ä½™ {len(missing_codes)} ä¸ªå¾…æŸ¥")
                except Exception as e:
                    logger.debug(f"[è‚¡ç¥¨åç§°] {fetcher.name} æ‰¹é‡è·å–å¤±è´¥: {e}")
                    continue
        
        # 3. é€ä¸ªè·å–å‰©ä½™çš„
        for code in list(missing_codes):
            name = self.get_stock_name(code)
            if name:
                result[code] = name
                missing_codes.discard(code)
        
        logger.info(f"[è‚¡ç¥¨åç§°] æ‰¹é‡è·å–å®Œæˆï¼ŒæˆåŠŸ {len(result)}/{len(stock_codes)}")
        return result

    def get_main_indices(self) -> List[Dict[str, Any]]:
        """è·å–ä¸»è¦æŒ‡æ•°å®æ—¶è¡Œæƒ…ï¼ˆè‡ªåŠ¨åˆ‡æ¢æ•°æ®æºï¼‰"""
        for fetcher in self._fetchers:
            try:
                data = fetcher.get_main_indices()
                if data:
                    logger.info(f"[{fetcher.name}] è·å–æŒ‡æ•°è¡Œæƒ…æˆåŠŸ")
                    return data
            except Exception as e:
                logger.warning(f"[{fetcher.name}] è·å–æŒ‡æ•°è¡Œæƒ…å¤±è´¥: {e}")
                continue
        return []

    def get_market_stats(self) -> Dict[str, Any]:
        """è·å–å¸‚åœºæ¶¨è·Œç»Ÿè®¡ï¼ˆè‡ªåŠ¨åˆ‡æ¢æ•°æ®æºï¼‰"""
        for fetcher in self._fetchers:
            try:
                data = fetcher.get_market_stats()
                if data:
                    logger.info(f"[{fetcher.name}] è·å–å¸‚åœºç»Ÿè®¡æˆåŠŸ")
                    return data
            except Exception as e:
                logger.warning(f"[{fetcher.name}] è·å–å¸‚åœºç»Ÿè®¡å¤±è´¥: {e}")
                continue
        return {}

    def get_sector_rankings(self, n: int = 5) -> Tuple[List[Dict], List[Dict]]:
        """è·å–æ¿å—æ¶¨è·Œæ¦œï¼ˆè‡ªåŠ¨åˆ‡æ¢æ•°æ®æºï¼‰"""
        for fetcher in self._fetchers:
            try:
                data = fetcher.get_sector_rankings(n)
                if data:
                    logger.info(f"[{fetcher.name}] è·å–æ¿å—æ’è¡ŒæˆåŠŸ")
                    return data
            except Exception as e:
                logger.warning(f"[{fetcher.name}] è·å–æ¿å—æ’è¡Œå¤±è´¥: {e}")
                continue
        return [], []
