# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡/æ¾³è‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - æœç´¢æœåŠ¡æ¨¡å—
===================================

èŒè´£ï¼š
1. æä¾›ç»Ÿä¸€çš„æ–°é—»æœç´¢æ¥å£
2. æ”¯æŒ Tavily å’Œ SerpAPI ä¸¤ç§æœç´¢å¼•æ“
3. å¤š Key è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»
4. æœç´¢ç»“æœç¼“å­˜å’Œæ ¼å¼åŒ–
"""

import logging
import random
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from itertools import cycle
import requests
from newspaper import Article, Config

logger = logging.getLogger(__name__)


def fetch_url_content(url: str, timeout: int = 5) -> str:
    """
    è·å– URL ç½‘é¡µæ­£æ–‡å†…å®¹ (ä½¿ç”¨ newspaper3k)
    """
    try:
        # é…ç½® newspaper3k
        config = Config()
        config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        config.request_timeout = timeout
        config.fetch_images = False  # ä¸ä¸‹è½½å›¾ç‰‡
        config.memoize_articles = False # ä¸ç¼“å­˜

        article = Article(url, config=config, language='zh') # é»˜è®¤ä¸­æ–‡ï¼Œä½†ä¹Ÿæ”¯æŒå…¶ä»–
        article.download()
        article.parse()

        # è·å–æ­£æ–‡
        text = article.text.strip()

        # ç®€å•çš„åå¤„ç†ï¼Œå»é™¤ç©ºè¡Œ
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        text = '\n'.join(lines)

        return text[:1500]  # é™åˆ¶è¿”å›é•¿åº¦
    except Exception as e:
        logger.debug(f"Fetch content failed for {url}: {e}")

    return ""


@dataclass
class SearchResult:
    """æœç´¢ç»“æœæ•°æ®ç±»"""
    title: str
    snippet: str  # æ‘˜è¦
    url: str
    source: str  # æ¥æºç½‘ç«™
    published_date: Optional[str] = None
    
    def to_text(self) -> str:
        """è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼"""
        date_str = f" ({self.published_date})" if self.published_date else ""
        return f"ã€{self.source}ã€‘{self.title}{date_str}\n{self.snippet}"


@dataclass 
class SearchResponse:
    """æœç´¢å“åº”"""
    query: str
    results: List[SearchResult]
    provider: str  # ä½¿ç”¨çš„æœç´¢å¼•æ“
    success: bool = True
    error_message: Optional[str] = None
    search_time: float = 0.0  # æœç´¢è€—æ—¶ï¼ˆç§’ï¼‰
    
    def to_context(self, max_results: int = 5) -> str:
        """å°†æœç´¢ç»“æœè½¬æ¢ä¸ºå¯ç”¨äº AI åˆ†æçš„ä¸Šä¸‹æ–‡"""
        if not self.success or not self.results:
            return f"æœç´¢ '{self.query}' æœªæ‰¾åˆ°ç›¸å…³ç»“æœã€‚"
        
        lines = [f"ã€{self.query} æœç´¢ç»“æœã€‘ï¼ˆæ¥æºï¼š{self.provider}ï¼‰"]
        for i, result in enumerate(self.results[:max_results], 1):
            lines.append(f"\n{i}. {result.to_text()}")
        
        return "\n".join(lines)


class BaseSearchProvider(ABC):
    """æœç´¢å¼•æ“åŸºç±»"""
    
    def __init__(self, api_keys: List[str], name: str):
        self._api_keys = api_keys
        self._name = name
        self._key_cycle = cycle(api_keys) if api_keys else None
        self._key_usage: Dict[str, int] = {key: 0 for key in api_keys}
        self._key_errors: Dict[str, int] = {key: 0 for key in api_keys}
    
    @property
    def name(self) -> str:
        return self._name
    
    @property
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ API Key"""
        return bool(self._api_keys)
    
    def _get_next_key(self) -> Optional[str]:
        if not self._key_cycle:
            return None
        
        # æœ€å¤šå°è¯•æ‰€æœ‰ key
        for _ in range(len(self._api_keys)):
            key = next(self._key_cycle)
            # è·³è¿‡é”™è¯¯æ¬¡æ•°è¿‡å¤šçš„ keyï¼ˆè¶…è¿‡ 3 æ¬¡ï¼‰
            if self._key_errors.get(key, 0) < 3:
                return key
        
        # æ‰€æœ‰ key éƒ½æœ‰é—®é¢˜ï¼Œé‡ç½®é”™è¯¯è®¡æ•°å¹¶è¿”å›ç¬¬ä¸€ä¸ª
        logger.warning(f"[{self._name}] æ‰€æœ‰ API Key éƒ½æœ‰é”™è¯¯è®°å½•ï¼Œé‡ç½®é”™è¯¯è®¡æ•°")
        self._key_errors = {key: 0 for key in self._api_keys}
        return self._api_keys[0] if self._api_keys else None
    
    def _record_success(self, key: str) -> None:
        self._key_usage[key] = self._key_usage.get(key, 0) + 1
        if key in self._key_errors and self._key_errors[key] > 0:
            self._key_errors[key] -= 1
    
    def _record_error(self, key: str) -> None:
        self._key_errors[key] = self._key_errors.get(key, 0) + 1
        logger.warning(f"[{self._name}] API Key {key[:8]}... é”™è¯¯è®¡æ•°: {self._key_errors[key]}")
    
    @abstractmethod
    def _do_search(self, query: str, api_key: str, max_results: int, days: int = 7) -> SearchResponse:
        pass
    
    def search(self, query: str, max_results: int = 5, days: int = 7) -> SearchResponse:
        api_key = self._get_next_key()
        if not api_key:
            return SearchResponse(
                query=query, results=[], provider=self._name, success=False,
                error_message=f"{self._name} æœªé…ç½® API Key"
            )
        
        start_time = time.time()
        try:
            response = self._do_search(query, api_key, max_results, days=days)
            response.search_time = time.time() - start_time
            
            if response.success:
                self._record_success(api_key)
                logger.info(f"[{self._name}] æœç´¢ '{query}' æˆåŠŸï¼Œè¿”å› {len(response.results)} æ¡ç»“æœ")
            else:
                self._record_error(api_key)
            
            return response
            
        except Exception as e:
            self._record_error(api_key)
            elapsed = time.time() - start_time
            logger.error(f"[{self._name}] æœç´¢ '{query}' å¤±è´¥: {e}")
            return SearchResponse(
                query=query, results=[], provider=self._name, success=False,
                error_message=str(e), search_time=elapsed
            )


class TavilySearchProvider(BaseSearchProvider):
    """Tavily æœç´¢å¼•æ“ (ASX ä¼˜åŒ–)"""
    
    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "Tavily")
    
    def _do_search(self, query: str, api_key: str, max_results: int, days: int = 7) -> SearchResponse:
        try:
            from tavily import TavilyClient
        except ImportError:
            return SearchResponse(query=query, results=[], provider=self.name, success=False, error_message="tavily-python æœªå®‰è£…")
        
        try:
            client = TavilyClient(api_key=api_key)
            response = client.search(
                query=query,
                search_depth="advanced",
                max_results=max_results,
                include_answer=False,
                include_raw_content=False,
                days=days,
            )
            
            results = []
            for item in response.get('results', []):
                results.append(SearchResult(
                    title=item.get('title', ''),
                    snippet=item.get('content', '')[:500],
                    url=item.get('url', ''),
                    source=self._extract_domain(item.get('url', '')),
                    published_date=item.get('published_date'),
                ))
            
            return SearchResponse(query=query, results=results, provider=self.name, success=True)
            
        except Exception as e:
            return SearchResponse(query=query, results=[], provider=self.name, success=False, error_message=str(e))
    
    @staticmethod
    def _extract_domain(url: str) -> str:
        try:
            from urllib.parse import urlparse
            return urlparse(url).netloc.replace('www.', '') or 'æœªçŸ¥æ¥æº'
        except:
            return 'æœªçŸ¥æ¥æº'


class SerpAPISearchProvider(BaseSearchProvider):
    """SerpAPI æœç´¢å¼•æ“"""
    
    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "SerpAPI")
    
    def _do_search(self, query: str, api_key: str, max_results: int, days: int = 7) -> SearchResponse:
        try:
            from serpapi import GoogleSearch
        except ImportError:
            return SearchResponse(query=query, results=[], provider=self.name, success=False, error_message="google-search-results æœªå®‰è£…")
        
        try:
            tbs = "qdr:w"
            if days <= 1: tbs = "qdr:d"
            elif days <= 30: tbs = "qdr:m"
            
            params = {
                "engine": "google", "q": query, "api_key": api_key,
                "google_domain": "google.com.hk", "hl": "zh-cn", "gl": "cn",
                "tbs": tbs, "num": max_results
            }
            
            search = GoogleSearch(params)
            response = search.get_dict()
            results = []
            
            # è§£æè‡ªç„¶æœç´¢ç»“æœ
            for item in response.get('organic_results', [])[:max_results]:
                results.append(SearchResult(
                    title=item.get('title', ''),
                    snippet=item.get('snippet', '')[:1000],
                    url=item.get('link', ''),
                    source=item.get('source', 'Google'),
                    published_date=item.get('date'),
                ))
            
            return SearchResponse(query=query, results=results, provider=self.name, success=True)
            
        except Exception as e:
            return SearchResponse(query=query, results=[], provider=self.name, success=False, error_message=str(e))


class BochaSearchProvider(BaseSearchProvider):
    """åšæŸ¥æœç´¢å¼•æ“"""
    
    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "Bocha")
    
    def _do_search(self, query: str, api_key: str, max_results: int, days: int = 7) -> SearchResponse:
        try:
            url = "https://api.bocha.cn/v1/web-search"
            headers = {'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'}
            freshness = "oneWeek"
            if days <= 1: freshness = "oneDay"
            elif days > 30: freshness = "oneYear"

            payload = {
                "query": query, "freshness": freshness,
                "summary": True, "count": min(max_results, 50)
            }
            
            response = requests.post(url, headers=headers, json=payload, timeout=10)
            if response.status_code != 200:
                return SearchResponse(query=query, results=[], provider=self.name, success=False, error_message=f"HTTP {response.status_code}: {response.text}")
            
            data = response.json()
            if data.get('code') != 200:
                return SearchResponse(query=query, results=[], provider=self.name, success=False, error_message=data.get('msg'))
                
            results = []
            for item in data.get('data', {}).get('webPages', {}).get('value', [])[:max_results]:
                results.append(SearchResult(
                    title=item.get('name', ''),
                    snippet=(item.get('summary') or item.get('snippet', ''))[:500],
                    url=item.get('url', ''),
                    source=item.get('siteName', ''),
                    published_date=item.get('datePublished'),
                ))
                
            return SearchResponse(query=query, results=results, provider=self.name, success=True)
            
        except Exception as e:
            return SearchResponse(query=query, results=[], provider=self.name, success=False, error_message=str(e))


class BraveSearchProvider(BaseSearchProvider):
    """Brave Search æœç´¢å¼•æ“"""

    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "Brave")

    def _do_search(self, query: str, api_key: str, max_results: int, days: int = 7) -> SearchResponse:
        try:
            headers = {'X-Subscription-Token': api_key, 'Accept': 'application/json'}
            freshness = "pw" # é»˜è®¤ä¸€å‘¨
            if days <= 1: freshness = "pd"
            elif days > 30: freshness = "py"
            
            params = {
                "q": query, "count": min(max_results, 20),
                "freshness": freshness, "search_lang": "en", "country": "US"
            }
            
            response = requests.get("https://api.search.brave.com/res/v1/web/search", headers=headers, params=params, timeout=10)
            if response.status_code != 200:
                return SearchResponse(query=query, results=[], provider=self.name, success=False, error_message=f"HTTP {response.status_code}")

            data = response.json()
            results = []
            for item in data.get('web', {}).get('results', [])[:max_results]:
                results.append(SearchResult(
                    title=item.get('title', ''),
                    snippet=item.get('description', '')[:500],
                    url=item.get('url', ''),
                    source="Brave",
                    published_date=item.get('age')
                ))
            
            return SearchResponse(query=query, results=results, provider=self.name, success=True)
            
        except Exception as e:
            return SearchResponse(query=query, results=[], provider=self.name, success=False, error_message=str(e))


class SearchService:
    """
    æœç´¢æœåŠ¡ (æ¾³æ´²ä¼˜åŒ–ç‰ˆ)
    """
    
    # å¢å¼ºæœç´¢å…³é”®è¯æ¨¡æ¿ï¼ˆæ¸¯è‚¡/ç¾è‚¡ è‹±æ–‡ï¼‰
    ENHANCED_SEARCH_KEYWORDS_EN = [
        "{name} stock price today",
        "{name} {code} latest quote trend",
        "{name} stock analysis chart",
        "{name} technical analysis",
        "{name} {code} performance volume",
    ]
    
    # å¢å¼ºæœç´¢å…³é”®è¯æ¨¡æ¿ï¼ˆAè‚¡ ä¸­æ–‡ï¼‰
    ENHANCED_SEARCH_KEYWORDS = [
        "{name} è‚¡ç¥¨ ä»Šæ—¥ è‚¡ä»·",
        "{name} {code} æœ€æ–° è¡Œæƒ… èµ°åŠ¿",
        "{name} è‚¡ç¥¨ åˆ†æ èµ°åŠ¿å›¾",
    ]
    
    def __init__(
        self,
        bocha_keys: Optional[List[str]] = None,
        tavily_keys: Optional[List[str]] = None,
        brave_keys: Optional[List[str]] = None,
        serpapi_keys: Optional[List[str]] = None,
    ):
        """åˆå§‹åŒ–æœç´¢æœåŠ¡ï¼ˆå·²é’ˆå¯¹æ¾³æ´²è‚¡ç¥¨ä¼˜åŒ–ï¼šTavily ä¼˜å…ˆï¼‰"""
        self._providers: List[BaseSearchProvider] = []

        # 1. Tavily ä¼˜å…ˆï¼ˆé’ˆå¯¹ ASX æ¾³æ´²è‚¡ç¥¨æœç´¢èƒ½åŠ›å¼ºï¼‰
        if tavily_keys:
            self._providers.append(TavilySearchProvider(tavily_keys))
            logger.info(f"å·²é…ç½® Tavily æœç´¢ï¼Œå…± {len(tavily_keys)} ä¸ª API Key")

        # 2. SerpAPI ç¬¬äºŒï¼ˆGoogle åŸç”Ÿæœç´¢ï¼‰
        if serpapi_keys:
            self._providers.append(SerpAPISearchProvider(serpapi_keys))
            logger.info(f"å·²é…ç½® SerpAPI æœç´¢ï¼Œå…± {len(serpapi_keys)} ä¸ª API Key")

        # 3. Brave Search ç¬¬ä¸‰
        if brave_keys:
            self._providers.append(BraveSearchProvider(brave_keys))
            logger.info(f"å·²é…ç½® Brave æœç´¢ï¼Œå…± {len(brave_keys)} ä¸ª API Key")

        # 4. Bocha é™è‡³æœ€åï¼ˆç›®å‰æ¬ è´¹ï¼Œä»…ä½œæœ€åå¤‡ä»½ï¼‰
        if bocha_keys:
            self._providers.append(BochaSearchProvider(bocha_keys))
            logger.info(f"å·²é…ç½® Bocha æœç´¢ï¼Œå…± {len(bocha_keys)} ä¸ª API Key")
        
        if not self._providers:
            logger.warning("æœªé…ç½®ä»»ä½•æœç´¢å¼•æ“ API Keyï¼Œæ–°é—»æœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨")

        self._cache: Dict[str, Tuple[float, 'SearchResponse']] = {}
        self._cache_ttl: int = 600

    @staticmethod
    def _is_foreign_stock(stock_code: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ¸¯è‚¡æˆ–ç¾è‚¡"""
        import re
        code = stock_code.strip()
        # ç¾è‚¡/æ¾³è‚¡ï¼š1-5ä¸ªå¤§å†™å­—æ¯ï¼Œå¯èƒ½åŒ…å«ç‚¹ï¼ˆå¦‚ BRK.B, CBA.AXï¼‰
        if re.match(r'^[A-Za-z]{1,5}(\.[A-Za-z]+)?$', code):
            return True
        # æ¸¯è‚¡
        if code.lower().startswith('hk') or (code.isdigit() and len(code) == 5):
            return True
        return False

    def _cache_key(self, query: str, max_results: int, days: int) -> str:
        return f"{query}|{max_results}|{days}"

    def _get_cached(self, key: str) -> Optional['SearchResponse']:
        entry = self._cache.get(key)
        if entry is None: return None
        ts, response = entry
        if time.time() - ts > self._cache_ttl:
            del self._cache[key]
            return None
        return response

    def _put_cache(self, key: str, response: 'SearchResponse') -> None:
        self._cache[key] = (time.time(), response)
    
    def search_stock_news(self, stock_code: str, stock_name: str, max_results: int = 5, focus_keywords: Optional[List[str]] = None) -> SearchResponse:
        today_weekday = datetime.now().weekday()
        search_days = 3 if today_weekday == 0 else (2 if today_weekday >= 5 else 1)

        is_foreign = self._is_foreign_stock(stock_code)
        if focus_keywords:
            query = " ".join(focus_keywords)
        elif is_foreign:
            query = f"{stock_name} {stock_code} stock latest news"
        else:
            query = f"{stock_name} {stock_code} è‚¡ç¥¨ æœ€æ–°æ¶ˆæ¯"

        logger.info(f"æœç´¢è‚¡ç¥¨æ–°é—»: {stock_name}({stock_code}), query='{query}'")
        
        cache_key = self._cache_key(query, max_results, search_days)
        cached = self._get_cached(cache_key)
        if cached: return cached

        for provider in self._providers:
            if not provider.is_available: continue
            response = provider.search(query, max_results, days=search_days)
            if response.success and response.results:
                self._put_cache(cache_key, response)
                return response
        
        return SearchResponse(query=query, results=[], provider="None", success=False, error_message="All providers failed")

    def search_stock_events(self, stock_code: str, stock_name: str, event_types: Optional[List[str]] = None) -> SearchResponse:
        if event_types is None:
            if self._is_foreign_stock(stock_code):
                event_types = ["earnings report", "insider selling", "quarterly results"]
            else:
                event_types = ["å¹´æŠ¥é¢„å‘Š", "å‡æŒå…¬å‘Š", "ä¸šç»©å¿«æŠ¥"]
        
        query = f"{stock_name} ({' OR '.join(event_types)})"
        for provider in self._providers:
            if not provider.is_available: continue
            response = provider.search(query, max_results=5)
            if response.success: return response
            
        return SearchResponse(query=query, results=[], provider="None", success=False, error_message="Events search failed")

    def search_comprehensive_intel(self, stock_code: str, stock_name: str, max_searches: int = 3) -> Dict[str, SearchResponse]:
        results = {}
        is_foreign = self._is_foreign_stock(stock_code)
        
        if is_foreign:
            dims = [
                {'name': 'latest_news', 'query': f"{stock_name} {stock_code} latest news events", 'desc': 'æœ€æ–°æ¶ˆæ¯'},
                {'name': 'market_analysis', 'query': f"{stock_name} analyst rating target price report", 'desc': 'æœºæ„åˆ†æ'},
                {'name': 'risk_check', 'query': f"{stock_name} risk insider selling lawsuit litigation", 'desc': 'é£é™©æ’æŸ¥'},
                {'name': 'earnings', 'query': f"{stock_name} earnings revenue profit growth forecast", 'desc': 'ä¸šç»©é¢„æœŸ'},
                {'name': 'industry', 'query': f"{stock_name} industry competitors market share outlook", 'desc': 'è¡Œä¸šåˆ†æ'},
            ]
        else:
            dims = [
                {'name': 'latest_news', 'query': f"{stock_name} æœ€æ–°æ–°é—»", 'desc': 'æœ€æ–°æ¶ˆæ¯'},
                {'name': 'market_analysis', 'query': f"{stock_name} ç ”æŠ¥ è¯„çº§", 'desc': 'æœºæ„åˆ†æ'},
                {'name': 'risk_check', 'query': f"{stock_name} åˆ©ç©º é£é™©", 'desc': 'é£é™©æ’æŸ¥'},
                {'name': 'earnings', 'query': f"{stock_name} ä¸šç»©é¢„å‘Š", 'desc': 'ä¸šç»©é¢„æœŸ'},
                {'name': 'industry', 'query': f"{stock_name} è¡Œä¸šåˆ†æ", 'desc': 'è¡Œä¸šåˆ†æ'},
            ]

        for dim in dims:
            # å§‹ç»ˆä¼˜å…ˆä½¿ç”¨ Tavily (å¦‚æœé…ç½®äº†ä¸”æ’åœ¨ç¬¬ä¸€ä½)
            for provider in self._providers:
                if not provider.is_available: continue
                resp = provider.search(dim['query'], max_results=3)
                results[dim['name']] = resp
                if resp.success: break # åªè¦æœ‰ä¸€ä¸ªæˆåŠŸå°±è·³å‡ºï¼Œè¿›è¡Œä¸‹ä¸€ä¸ªç»´åº¦
                time.sleep(0.5)
                
        return results

    def format_intel_report(self, intel_results: Dict[str, SearchResponse], stock_name: str) -> str:
        lines = [f"ã€{stock_name} æƒ…æŠ¥æœç´¢ç»“æœã€‘"]
        order = ['latest_news', 'market_analysis', 'risk_check', 'earnings', 'industry']
        
        for dim_name in order:
            if dim_name not in intel_results: continue
            resp = intel_results[dim_name]
            dim_desc = {'latest_news': 'ğŸ“° æœ€æ–°æ¶ˆæ¯', 'market_analysis': 'ğŸ“ˆ æœºæ„åˆ†æ', 'risk_check': 'âš ï¸ é£é™©æ’æŸ¥', 'earnings': 'ğŸ“Š ä¸šç»©é¢„æœŸ', 'industry': 'ğŸ­ è¡Œä¸šåˆ†æ'}.get(dim_name, dim_name)
            
            lines.append(f"\n{dim_desc} (æ¥æº: {resp.provider}):")
            if resp.success and resp.results:
                for i, r in enumerate(resp.results[:3], 1):
                    date_str = f" [{r.published_date}]" if r.published_date else ""
                    lines.append(f"  {i}. {r.title}{date_str}")
            else:
                lines.append("  æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
        
        return "\n".join(lines)


# === ä¾¿æ·å‡½æ•° ===
_search_service: Optional[SearchService] = None

def get_search_service() -> SearchService:
    global _search_service
    if _search_service is None:
        from src.config import get_config
        config = get_config()
        _search_service = SearchService(
            bocha_keys=config.bocha_api_keys,
            tavily_keys=config.tavily_api_keys,
            brave_keys=config.brave_api_keys,
            serpapi_keys=config.serpapi_keys,
        )
    return _search_service

def reset_search_service() -> None:
    global _search_service
    _search_service = None

if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)
    service = get_search_service()
    if service.is_available:
        print("=== æµ‹è¯•è‚¡ç¥¨æ–°é—»æœç´¢ ===")
        # æµ‹è¯•æ¾³è‚¡ä»£ç 
        response = service.search_stock_news("CBA.AX", "CommBank")
        print(f"æœç´¢çŠ¶æ€: {'æˆåŠŸ' if response.success else 'å¤±è´¥'}")
        print(f"æœç´¢å¼•æ“: {response.provider}")
        print("\n" + response.to_context())
